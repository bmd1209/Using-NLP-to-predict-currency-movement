{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cfb2f54-1ce6-4cb9-9371-a20c0cf82859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the vader library for sentiment analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import OpenBlender\n",
    "import json\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "from pathlib import Path\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33c598fb-010d-4f2e-a563-3f0f00e059a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "# import these modules \n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# nltk.sentiment.vader\n",
    "\n",
    "ps = PorterStemmer() # stemming\n",
    "wordnet_lemmatizer = WordNetLemmatizer()  #Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "260eda81-33b9-4d4f-a5c7-7c1c1bbacec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sentiment score applying the vaderSentiment functions\n",
    "file_path = Path(\"crypto_id_dataset_news.csv\")\n",
    "initial_db2 = pd.read_csv(file_path )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46f10718-8a45-4a79-a3b1-9d1d65df1ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of      Unnamed: 0                 date     timestamp     close  target  \\\n",
       "0             0  18-09-2021 17:00:00  1.631984e+09  48292.74       1   \n",
       "1             1  17-09-2021 17:00:00  1.631898e+09  47299.98       0   \n",
       "2             2  16-09-2021 17:00:00  1.631812e+09  47737.82       0   \n",
       "3             3  15-09-2021 17:00:00  1.631725e+09  48121.41       1   \n",
       "4             4  14-09-2021 17:00:00  1.631639e+09  47111.52       1   \n",
       "..          ...                  ...           ...       ...     ...   \n",
       "575         575  05-01-2020 17:00:00  1.578244e+09   7358.75       1   \n",
       "576         576  04-01-2020 17:00:00  1.578157e+09   7354.11       1   \n",
       "577         577  03-01-2020 17:00:00  1.578071e+09   7344.96       1   \n",
       "578         578  02-01-2020 17:00:00  1.577984e+09   6965.71       0   \n",
       "579         579  01-01-2020 17:00:00  1.577898e+09   7200.85       1   \n",
       "\n",
       "     VEC.timestamp  VEC.CRYPTOCURR.text_COUNT_last1days:bitcoin  \\\n",
       "0       1631984400                                            4   \n",
       "1       1631898000                                            4   \n",
       "2       1631811600                                            4   \n",
       "3       1631725200                                            6   \n",
       "4       1631638800                                            3   \n",
       "..             ...                                          ...   \n",
       "575     1578243600                                            1   \n",
       "576     1578157200                                            1   \n",
       "577     1578070800                                            1   \n",
       "578     1577984400                                            0   \n",
       "579     1577898000                                            0   \n",
       "\n",
       "                 VEC.CRYPTOCURR.text_last1days:bitcoin  \n",
       "0    ['ray dalio says he thinks governments will ki...  \n",
       "1    ['hungary unveiled the worlds first statue of ...  \n",
       "2    ['#bitcoin has a low maintenance cost compared...  \n",
       "3    ['#crypto is the only asset space where you ha...  \n",
       "4    ['the us dollar is expected to lose at least 5...  \n",
       "..                                                 ...  \n",
       "575  ['a burger king location in venezuela is now a...  \n",
       "576                             ['bullish on bitcoin']  \n",
       "577  ['they can kill the 2nd most powerful person i...  \n",
       "578                                                 []  \n",
       "579                                                 []  \n",
       "\n",
       "[580 rows x 8 columns]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_db2.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe5856ac-a7b7-4438-8a2e-6cff0fed891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Happy Emoticons\n",
    "emoticons_happy = set([\n",
    "    ':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}',\n",
    "    ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',\n",
    "    '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',\n",
    "    'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)',\n",
    "    '<3'\n",
    "    ])\n",
    " \n",
    "# Sad Emoticons\n",
    "emoticons_sad = set([\n",
    "    ':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\n",
    "    ':-[', ':-<', '=\\\\', '=/', '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c',\n",
    "    ':c', ':{', '>:\\\\', ';('\n",
    "    ])\n",
    "\n",
    "#combine sad and happy emoticons\n",
    "emoticons = emoticons_happy.union(emoticons_sad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5f1035-08fb-46ec-957f-b03e87602576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "168cefec-2197-4e1a-8301-0c2e38b19f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{':^*', 'x-D', '>:[', ':L', \":'-(\", \":'-)\", '=3', '>:P', 'X-P', ':^)', ':-c', ':<', '8)', ':p', '<3', ';)', '=-3', ':*', 'xp', ':-)', '>:\\\\', ':[', '8-D', '>:-)', 'XD', ':@', 'x-p', ':-D', '>.<', ':(', \":'(\", '=D', '>;)', '=\\\\', \":')\", ':S', ':-))', ':)', ':c)', 'XP', '>:/', ':-b', '=]', ':-<', ':{', ':]', '=/', ':-(', ':\\\\', ':3', ':}', ':b', '=)', 'X-D', ':-||', ':-P', ':P', ':c', '=-D', ':-p', '>:)', ':o)', '8D', ':-[', '=L', '>:(', 'xD', '=p', ':>', ':D', ':-/', ';('}\n"
     ]
    }
   ],
   "source": [
    "print(emoticons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a18584c2-9420-4193-a506-e6f4fd9d4fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Emojis pattern\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "                u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                u\"\\U00002702-\\U000027B0\"\n",
    "                u\"\\U000024C2-\\U0001F251\"\n",
    "                u\"\\U0001f926-\\U0001f937\"\n",
    "                u'\\U00010000-\\U0010ffff'\n",
    "                u\"\\u200d\"\n",
    "                u\"\\u2640-\\u2642\"\n",
    "                u\"\\u2600-\\u2B55\"\n",
    "                u\"\\u23cf\"\n",
    "                u\"\\u23e9\"\n",
    "                u\"\\u231a\"\n",
    "                u\"\\u3030\"\n",
    "                u\"\\ufe0f\"\n",
    "    \"]+\", flags=re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6db3b46c-273c-44a7-8a88-5a71ce22fb38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.compile(r'[üòÄ-üôèüåÄ-üóøüöÄ-\\U0001f6ff\\U0001f1e0-üáø‚úÇ-‚û∞‚ìÇ-üâëü§¶-ü§∑êÄÄ-\\U0010ffff\\u200d‚ôÄ-‚ôÇ‚òÄ-‚≠ï‚èè‚è©‚åö„Ä∞Ô∏è]+',\n",
       "re.UNICODE)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89746f84-e1e0-4e2d-af87-907133a449ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~‚ñº'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# punctuations pattern\n",
    "punctuation_pattern = string.punctuation + \"‚ñº\"\n",
    "punctuation_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe3275ac-57cb-406b-9fb5-751c463e6879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'did', \"hadn't\", \"he'll\", \"here's\", 'btc', 'from', \"he'd\", 'which', 'its', 'the', 'all', 'most', 'just', 'some', 'his', 'our', \"it's\", 'hers', 'their', 'do', 'again', 'above', \"i'd\", 'those', 'being', 'before', \"when's\", 'of', 'hence', 'both', 'does', 'against', 'ourselves', \"what's\", \"she's\", 'after', 'crypto', 'this', \"you'd\", \"can't\", \"haven't\", \"won't\", \"isn't\", 'until', \"she'll\", 'com', 'out', 'he', 'because', 'in', 'him', 'over', 'yours', 'cannot', \"don't\", 'when', 'here', \"who's\", \"i've\", 'below', 'on', 'can', 'me', \"she'd\", 'why', 'same', 'however', \"they'd\", 'or', 'these', 'up', 'your', 'her', 'it', 'each', \"where's\", 'since', 'by', 'what', 'yourselves', 'like', 'through', \"he's\", 'blockchain', 'am', 'herself', 'during', 'be', 'further', 'into', 'such', 'you', 'as', 'where', \"you'll\", 'about', \"there's\", 'an', 'should', \"doesn't\", \"we'd\", 'could', \"we're\", 'with', 'are', 'i', 'myself', 'there', 'else', 'ever', 'were', 'she', 'would', 'www', 'otherwise', 'shall', 'for', 'theirs', 'get', 'we', 'doing', 'having', 'k', 'is', \"mustn't\", 'they', \"we'll\", \"you've\", \"they've\", 'than', 'but', 'himself', \"hasn't\", 'was', 'who', 'r', 'not', 'only', 'yourself', 'themselves', \"shan't\", 'ought', 'and', 'to', 'ours', \"that's\", 'while', 'my', \"you're\", 'them', 'any', 'off', 'very', 'also', \"didn't\", 'how', \"weren't\", 'then', \"they're\", 'at', \"shouldn't\", 'down', \"wasn't\", \"wouldn't\", \"couldn't\", \"aren't\", 'have', 'between', 'few', 'cryptocurrency', 'own', 'http', \"how's\", \"we've\", 'itself', 'no', 'whom', 'therefore', 'if', \"i'll\", 'has', 'too', 'more', 'had', 'that', 'been', 'a', \"let's\", 'once', 'under', 'nor', \"they'll\", 'so', 'other', \"why's\", 'bitcoin', \"i'm\"}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "stopwords_re = set(STOPWORDS)\n",
    "update_list = [\"btc\", \"bitcoin\",\"blockchain\", \"crypto\",\"cryptocurrency\"]\n",
    "stopwords_re.update(update_list)\n",
    "print(stopwords_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb9dc3b5-bddf-4cb5-be55-fc2f899e7b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "clean_tweets()\n",
    "contains: remove links, tokenize, reomve non-ASCII chars, convert to lower case, remove stop_words, remove \n",
    "'''\n",
    "def clean_tweets(tweet):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # remove links\n",
    "    tweet = re.sub(r'http\\S+', '', tweet)\n",
    "   \n",
    "    #after tweepy preprocessing the colon left remain after removing mentions\n",
    "    #or RT sign in the import re\n",
    "   \n",
    "    tweet = re.sub(r':', '', tweet)\n",
    "    tweet = re.sub(r'‚Äö√Ñ¬∂', '', tweet)\n",
    "    tweet = re.sub(r'([0-9])\\w+','',tweet)\n",
    "    #replace consecutive non-ASCII characters with a space\n",
    "    tweet = re.sub(r'[^\\x00-\\x7F]+',' ', tweet)\n",
    " \n",
    "    #remove emojis from tweet\n",
    "    tweet = emoji_pattern.sub(r'', tweet)\n",
    "    \n",
    "    word_tokens = word_tokenize(tweet)\n",
    " \n",
    "    \n",
    "    #tweet = re.sub(r\"\\b\\w+\\b\",' ', tweet)\n",
    " \n",
    "    #filter using NLTK library append it to a string\n",
    "    #filtered_tweet = [w for w in word_tokens if not w in stop_words]\n",
    "    filtered_tweet = []\n",
    " \n",
    "    #looping through conditions\n",
    "    for w in word_tokens:\n",
    "        # convert to lower case\n",
    "        w = w.lower()\n",
    "        # lemmanization\n",
    "        w = wordnet_lemmatizer.lemmatize(w)\n",
    "        #check tokens against stop words , emoticons and punctuations\n",
    "        if w not in stop_words and w not in emoticons and w not in punctuation_pattern:\n",
    "            filtered_tweet.append(w)\n",
    "    return ' '.join(filtered_tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77adb208-32b5-4464-aa54-483c0ea5e0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the clean_tweet() function on the clean_text column \n",
    "initial_db2['clean_text'] = initial_db2['VEC.CRYPTOCURR.text_last1days:bitcoin'].apply(clean_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "427d0019-c641-4b35-b041-182686cd437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# show last 5 clean_text \n",
    "initial_db2['clean_text'].tail()\n",
    "initial_db2.to_csv(r'cleaned_text_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409b5596-0df5-477e-afeb-863ae186592e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sentiment score applying the vaderSentiment functions\n",
    "initial_db2['sentiment'] = initial_db2['VEC.CRYPTOCURR.text_last1days:bitcoin'].apply(analyzer.polarity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e450f047-5724-4f2d-a78e-5bb932f56b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from imageio import imread\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "476059e7-c94c-42c0-9d7d-ba3aee5deead",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-45-ef4e4cc5ce4e>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-45-ef4e4cc5ce4e>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    text = re.findall(r\"\\b\\w+\\b\", text,flags=re.UNICODE)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# join tweets to a single stringif row['lang'] == 'en')\n",
    "text = ' '.join(row['clean_text'] for index, row in initial_db2.iterrows() \n",
    "text = re.findall(r\"\\b\\w+\\b\", text,flags=re.UNICODE)\n",
    "text = \" \".join(t for t in text)\n",
    "\n",
    "#re.findall\treturns all the matches as a list\n",
    "#\\b\trestricts the match to the start/end of words\n",
    "#\\w\tMatch word character, same as [a-zA-Z0-9_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d31a88b5-1052-4ec1-8ed5-d7f674b2458c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11ed105b-9ac5-4bf7-b3fc-1b5eb9afce07",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-20ae5913b370>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m                \u001b[0mstopwords\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontour_width\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontour_color\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'steelblue'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1800\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1400\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregexp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mr\"\\b\\w+\\b\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m               font_path='../Font/Symbola.ttf').generate(text)\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "# read the mask image\n",
    "# taken from\n",
    "#twitter_mask = imread('../Image/twitter_mask.png', flatten=True)\n",
    "\n",
    "\n",
    "wc = WordCloud(background_color=\"white\", max_words=600,\n",
    "               stopwords=stopwords, contour_width=3, contour_color='steelblue',\n",
    "               width=1800, height=1400, regexp=r\"\\b\\w+\\b\",\n",
    "              font_path='../Font/Symbola.ttf').generate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56200d5-d219-4766-bb60-9d6936a7917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_db2['sentiment_comp'] = [c['compound'] for c in initial_db2['sentiment']]\n",
    "initial_db2['sentiment_pos'] = [c['pos'] for c in initial_db2['sentiment']]\n",
    "initial_db2['sentiment_neg'] = [c['neg'] for c in initial_db2['sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9203d2c6-6632-416e-829a-b7ead9fc1792",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path =  Path(\"Bitcoin_prices_target.csv\")\n",
    "btc_market = pd.read_csv(file_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527f269c-65d9-4702-b702-ed76cada44d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = initial_db2.merge(btc_market, on = 'timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb43e7d-e6eb-46fb-a0ae-ffc1e5755dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(r'combined_df.csv')\n",
    "print(combined_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d67282-e531-4d52-aa2c-4e3e52174e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [combined_df[\"timestamp\"], combined_df[\"close_x\"],combined_df[\"target_x\"],combined_df[\"sentiment_comp\"], combined_df[\"sentiment_neg\"], combined_df[\"sentiment_pos\"]]\n",
    "\n",
    "df3 = pd.concat(data, axis=1)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd9aa80-e5d9-48e7-b4df-f5500f0c49ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['target_x', 'sentiment_pos', 'sentiment_neg','sentiment_comp']\n",
    "combined_df[features].corr()['target_x']\n",
    "df_anchor = combined_df[features].corr()['target_x']\n",
    "print(df_anchor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a8684c-6e31-4dda-b835-2fc5da4fb2f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
